#!/usr/bin/env python3
"""
Backfill Settlement Reports from SP-API

Pulls all available settlement reports going back to a specified date.
Default: January 2024 (matching GorillaROI historical data).

Settlement reports are auto-generated by Amazon every ~2 weeks.
At ~26 reports/year × 3 marketplaces = ~78 reports/year.
Each download takes ~5 seconds + parsing. Full backfill ~30-45 minutes.

This script automatically skips already-processed settlements (idempotent).

Usage:
    python backfill_settlements.py                       # Default: since Jan 2024
    python backfill_settlements.py --since 2025-01-01    # Custom start date
    python backfill_settlements.py --marketplace USA     # Single marketplace
    python backfill_settlements.py --dry-run             # Test without DB writes

Environment Variables Required:
    SP_LWA_CLIENT_ID      - Login With Amazon Client ID
    SP_LWA_CLIENT_SECRET  - Login With Amazon Client Secret
    SP_REFRESH_TOKEN_NA   - North America refresh token
    SUPABASE_URL          - Supabase project URL
    SUPABASE_SERVICE_KEY  - Supabase service role key
"""

import os
import sys
import argparse
import time
from datetime import date, datetime
from typing import Dict, List, Any

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.auth import get_access_token
from utils.financial_reports import (
    list_settlement_reports,
    download_settlement_report,
    parse_settlement_rows,
    FINANCIAL_REPORT_TYPES
)
from utils.inventory_reports import MARKETPLACE_IDS
from utils.db import (
    create_data_import,
    update_data_import,
    create_financial_pull_record,
    update_financial_pull_status,
    get_processed_settlement_ids,
    upsert_settlement_transactions,
    upsert_settlement_summary,
    MARKETPLACE_UUIDS,
)

# Default backfill start
DEFAULT_SINCE = "2024-01-01"

# Rate limits
DOWNLOAD_DELAY = 10       # Seconds between report downloads (increased from 5s - was getting 429s)

# GitHub Actions timeout safety
MAX_RUNTIME_SECONDS = 5.5 * 60 * 60  # 5.5 hours (GitHub max is 6)


def backfill_settlements(
    access_token: str,
    since_date: str,
    region: str = "NA",
    dry_run: bool = False,
    start_time: float = None,
    list_marketplace: str = "USA"
) -> Dict[str, Any]:
    """
    Backfill all settlement reports since a date.

    Amazon's LIST API returns ALL NA-region settlements regardless of
    marketplace filter. Each report contains transactions for multiple
    marketplaces. This function processes each report once and attributes
    rows to the correct marketplace using the marketplace-name field.

    Args:
        access_token: Valid SP-API access token
        since_date: ISO date string
        region: API region
        dry_run: If True, don't write to database
        start_time: Script start time for timeout checking
        list_marketplace: Marketplace to use for LIST API call

    Returns:
        Dict with backfill statistics
    """
    report_type = FINANCIAL_REPORT_TYPES["SETTLEMENT"]
    mp_start = time.time()

    print(f"\n{'='*60}")
    print(f"Backfilling Settlement Reports — NA Region")
    print(f"Since: {since_date}")
    print(f"{'='*60}")

    # Step 1: List ALL available reports since the backfill date
    try:
        reports = list_settlement_reports(
            access_token, list_marketplace, region, since_date, max_results=100
        )
    except Exception as e:
        print(f"  ✗ Error listing reports: {e}")
        return {
            "status": "failed",
            "marketplace": "NA",
            "error": str(e),
            "reports_processed": 0,
            "reports_skipped": 0,
            "total_transactions": 0
        }

    print(f"  Found {len(reports)} total settlement reports")

    if not reports:
        return {
            "status": "no_data",
            "marketplace": "NA",
            "reports_processed": 0,
            "reports_skipped": 0,
            "total_transactions": 0
        }

    # Step 2: Get already-processed settlement IDs (globally)
    if not dry_run:
        processed_ids = get_processed_settlement_ids()
        processed_set = set(processed_ids)
        print(f"  Already processed: {len(processed_set)} settlements")
    else:
        processed_set = set()

    # Step 3: Process reports newest-first (most recent data first)
    reports.sort(key=lambda r: r.get("createdTime", ""), reverse=True)

    reports_processed = 0
    reports_skipped = 0
    total_transactions = 0
    errors = []

    for i, report in enumerate(reports):
        # Check timeout
        if start_time and (time.time() - start_time) > MAX_RUNTIME_SECONDS:
            print(f"\n  ⏱️  Approaching timeout limit — stopping.")
            print(f"  Processed {reports_processed} reports so far. Will continue next run.")
            break

        report_id = report.get("reportId", "")
        report_doc_id = report.get("reportDocumentId", "")
        created_time = report.get("createdTime", "")

        if not report_doc_id:
            continue

        print(f"\n  [{i+1}/{len(reports)}] Report: {report_id}")
        print(f"    Created: {created_time}")

        try:
            # Rate limit
            if reports_processed > 0 or reports_skipped > 0:
                time.sleep(DOWNLOAD_DELAY)

            # Download report
            rows = download_settlement_report(access_token, report_doc_id, region)

            if not rows:
                print(f"    ⚠️  Empty report — skipping")
                continue

            # Get settlement ID
            settlement_id = (rows[0].get("settlement-id") or "").strip()
            if not settlement_id:
                continue

            print(f"    Settlement: {settlement_id} ({len(rows)} rows)")

            # Skip if already processed
            if settlement_id in processed_set:
                print(f"    ⏭️  Already processed")
                reports_skipped += 1
                continue

            if dry_run:
                transactions, summary = parse_settlement_rows(
                    rows, MARKETPLACE_UUIDS.get("USA", ""),
                    marketplace_uuids=MARKETPLACE_UUIDS
                )
                # Count by marketplace
                mp_counts = {}
                for tx in transactions:
                    mp_id = tx["marketplace_id"]
                    mp_counts[mp_id] = mp_counts.get(mp_id, 0) + 1
                mp_labels = {v: k for k, v in MARKETPLACE_UUIDS.items()}
                mp_summary = ", ".join(
                    f"{mp_labels.get(mp_id, mp_id)}: {count}"
                    for mp_id, count in sorted(mp_counts.items(), key=lambda x: -x[1])
                )
                period = ""
                if summary:
                    period = (f" ({summary.get('settlement_start_date', '?')}"
                              f" to {summary.get('settlement_end_date', '?')})")
                print(f"    [DRY RUN] {len(transactions)} transactions ({mp_summary}){period}")
                total_transactions += len(transactions)
                reports_processed += 1
                continue

            # Create tracking
            import_id = create_data_import(
                "USA",
                date.today(),
                import_type="sp_api_settlement"
            )

            pull_id = create_financial_pull_record(
                marketplace_code="USA",
                report_type=report_type,
                pull_date=date.today(),
                import_id=import_id,
                settlement_id=settlement_id,
                report_id=report_id,
                report_document_id=report_doc_id
            )

            # Parse and upsert with per-row marketplace attribution
            transactions, summary = parse_settlement_rows(
                rows, MARKETPLACE_UUIDS.get("USA", ""),
                import_id=import_id,
                marketplace_uuids=MARKETPLACE_UUIDS
            )

            # Log marketplace breakdown
            mp_counts = {}
            for tx in transactions:
                mp_id = tx["marketplace_id"]
                mp_counts[mp_id] = mp_counts.get(mp_id, 0) + 1
            mp_labels = {v: k for k, v in MARKETPLACE_UUIDS.items()}
            for mp_id, count in sorted(mp_counts.items(), key=lambda x: -x[1]):
                print(f"    → {mp_labels.get(mp_id, mp_id)}: {count} transactions")

            tx_count = upsert_settlement_transactions(transactions)
            print(f"    ✅ {tx_count} transactions")

            if summary:
                upsert_settlement_summary(summary)
                print(f"    ✅ Summary: {summary.get('settlement_start_date', '?')} "
                      f"to {summary.get('settlement_end_date', '?')}, "
                      f"total: {summary.get('total_amount', '?')} "
                      f"{summary.get('currency_code', '?')}")

            # Update tracking
            processing_time = int((time.time() - mp_start) * 1000)
            update_financial_pull_status(
                pull_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )
            update_data_import(
                import_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )

            total_transactions += tx_count
            reports_processed += 1
            processed_set.add(settlement_id)

        except Exception as e:
            error_msg = str(e)
            print(f"    ✗ Error: {error_msg}")
            errors.append({"report_id": report_id, "error": error_msg})

    processing_time = int((time.time() - mp_start) * 1000)

    return {
        "status": "completed" if not errors else "partial",
        "marketplace": "NA",
        "reports_found": len(reports),
        "reports_processed": reports_processed,
        "reports_skipped": reports_skipped,
        "total_transactions": total_transactions,
        "errors": len(errors),
        "processing_time_ms": processing_time
    }


def main():
    parser = argparse.ArgumentParser(
        description="Backfill Settlement Reports from SP-API"
    )
    parser.add_argument(
        "--since",
        type=str,
        default=DEFAULT_SINCE,
        help=f"Backfill reports since this date (YYYY-MM-DD). Default: {DEFAULT_SINCE}"
    )
    parser.add_argument(
        "--marketplace",
        type=str,
        help="Marketplace to use for LIST API call (default: USA). "
             "Note: All NA settlements are returned regardless of marketplace."
    )
    parser.add_argument(
        "--region",
        type=str,
        default="NA",
        choices=["NA", "EU", "FE", "UAE"],
        help="Region to pull (NA, EU, FE). Default: NA"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Download and parse but don't write to database"
    )

    args = parser.parse_args()
    region = args.region.upper()

    since_date = f"{args.since}T00:00:00Z"

    # Marketplace for listing — settlements are per-region, any marketplace in the region works
    DEFAULT_LIST_MARKETPLACE = {"NA": "USA", "EU": "UK", "FE": "AU", "UAE": "UAE"}
    list_marketplace = (args.marketplace or DEFAULT_LIST_MARKETPLACE.get(region, "USA")).upper()
    if list_marketplace not in MARKETPLACE_IDS:
        print(f"Error: Invalid marketplace '{list_marketplace}'")
        sys.exit(1)

    print("=" * 60)
    print("SETTLEMENT REPORT BACKFILL")
    print(f"Region: {region}")
    print(f"Since: {args.since}")
    print(f"List marketplace: {list_marketplace} (all {region} settlements returned)")
    print(f"Dry run: {args.dry_run}")
    print("=" * 60)

    # Get access token
    print("\nGetting access token...")
    access_token = get_access_token(region=region)
    print("✓ Access token obtained")

    script_start = time.time()

    # Process all settlement reports (single run for entire region)
    result = backfill_settlements(
        access_token,
        since_date,
        region=region,
        dry_run=args.dry_run,
        start_time=script_start,
        list_marketplace=list_marketplace
    )

    # Summary
    print("\n" + "=" * 60)
    print("BACKFILL SUMMARY")
    print("=" * 60)

    status = result["status"]
    reports_processed = result.get("reports_processed", 0)
    skipped = result.get("reports_skipped", 0)
    transactions = result.get("total_transactions", 0)
    found = result.get("reports_found", 0)

    if status == "failed":
        print(f"  ✗ {result.get('error', 'Unknown error')}")
    else:
        icon = "✓" if status in ["completed", "dry_run"] else "⚠️"
        print(f"  {icon} {reports_processed} new / "
              f"{skipped} skipped / {found} total found, "
              f"{transactions} transactions")

    total_time = int((time.time() - script_start))
    print(f"Time: {total_time // 60}m {total_time % 60}s")

    if status == "failed":
        sys.exit(1)


if __name__ == "__main__":
    main()
