#!/usr/bin/env python3
"""
Backfill Settlement Reports from SP-API

Pulls all available settlement reports going back to a specified date.
Default: January 2024 (matching GorillaROI historical data).

Settlement reports are auto-generated by Amazon every ~2 weeks.
At ~26 reports/year × 3 marketplaces = ~78 reports/year.
Each download takes ~5 seconds + parsing. Full backfill ~30-45 minutes.

This script automatically skips already-processed settlements (idempotent).

Usage:
    python backfill_settlements.py                       # Default: since Jan 2024
    python backfill_settlements.py --since 2025-01-01    # Custom start date
    python backfill_settlements.py --marketplace USA     # Single marketplace
    python backfill_settlements.py --dry-run             # Test without DB writes

Environment Variables Required:
    SP_LWA_CLIENT_ID      - Login With Amazon Client ID
    SP_LWA_CLIENT_SECRET  - Login With Amazon Client Secret
    SP_REFRESH_TOKEN_NA   - North America refresh token
    SUPABASE_URL          - Supabase project URL
    SUPABASE_SERVICE_KEY  - Supabase service role key
"""

import os
import sys
import argparse
import time
from datetime import date, datetime
from typing import Dict, List, Any

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.auth import get_access_token
from utils.financial_reports import (
    list_settlement_reports,
    download_settlement_report,
    parse_settlement_rows,
    FINANCIAL_REPORT_TYPES
)
from utils.inventory_reports import MARKETPLACE_IDS
from utils.db import (
    get_supabase_client,
    create_data_import,
    update_data_import,
    create_financial_pull_record,
    update_financial_pull_status,
    get_processed_settlement_ids,
    upsert_settlement_transactions,
    upsert_settlement_summary,
    MARKETPLACE_UUIDS,
)

# Default marketplaces
DEFAULT_MARKETPLACES = ["USA", "CA", "MX"]

# Default backfill start
DEFAULT_SINCE = "2024-01-01"

# Rate limits
DOWNLOAD_DELAY = 5        # Seconds between report downloads
MARKETPLACE_DELAY = 10    # Seconds between marketplaces

# GitHub Actions timeout safety
MAX_RUNTIME_SECONDS = 5.5 * 60 * 60  # 5.5 hours (GitHub max is 6)


def backfill_marketplace(
    access_token: str,
    marketplace_code: str,
    since_date: str,
    region: str = "NA",
    dry_run: bool = False,
    start_time: float = None
) -> Dict[str, Any]:
    """
    Backfill all settlement reports for a marketplace since a date.

    Automatically skips already-processed settlement IDs.

    Args:
        access_token: Valid SP-API access token
        marketplace_code: Marketplace code
        since_date: ISO date string
        region: API region
        dry_run: If True, don't write to database
        start_time: Script start time for timeout checking

    Returns:
        Dict with backfill statistics
    """
    report_type = FINANCIAL_REPORT_TYPES["SETTLEMENT"]
    marketplace_id = MARKETPLACE_UUIDS[marketplace_code]
    mp_start = time.time()

    print(f"\n{'='*60}")
    print(f"Backfilling Settlement Reports: {marketplace_code}")
    print(f"Since: {since_date}")
    print(f"{'='*60}")

    # Step 1: List ALL available reports since the backfill date
    try:
        reports = list_settlement_reports(
            access_token, marketplace_code, region, since_date, max_results=100
        )
    except Exception as e:
        print(f"  ✗ Error listing reports: {e}")
        return {
            "status": "failed",
            "marketplace": marketplace_code,
            "error": str(e),
            "reports_processed": 0,
            "reports_skipped": 0,
            "total_transactions": 0
        }

    print(f"  Found {len(reports)} total settlement reports")

    if not reports:
        return {
            "status": "no_data",
            "marketplace": marketplace_code,
            "reports_processed": 0,
            "reports_skipped": 0,
            "total_transactions": 0
        }

    # Step 2: Get already-processed settlement IDs
    if not dry_run:
        processed_ids = get_processed_settlement_ids(marketplace_code)
        processed_set = set(processed_ids)
        print(f"  Already processed: {len(processed_set)} settlements")
    else:
        processed_set = set()

    # Step 3: Process reports newest-first (most recent data first)
    reports.sort(key=lambda r: r.get("createdTime", ""), reverse=True)

    reports_processed = 0
    reports_skipped = 0
    total_transactions = 0
    errors = []

    for i, report in enumerate(reports):
        # Check timeout
        if start_time and (time.time() - start_time) > MAX_RUNTIME_SECONDS:
            print(f"\n  ⏱️  Approaching timeout limit — stopping.")
            print(f"  Processed {reports_processed} reports so far. Will continue next run.")
            break

        report_id = report.get("reportId", "")
        report_doc_id = report.get("reportDocumentId", "")
        created_time = report.get("createdTime", "")

        if not report_doc_id:
            continue

        print(f"\n  [{i+1}/{len(reports)}] Report: {report_id}")
        print(f"    Created: {created_time}")

        try:
            # Rate limit
            if reports_processed > 0 or reports_skipped > 0:
                time.sleep(DOWNLOAD_DELAY)

            # Download report
            rows = download_settlement_report(access_token, report_doc_id, region)

            if not rows:
                print(f"    ⚠️  Empty report — skipping")
                continue

            # Get settlement ID
            settlement_id = rows[0].get("settlement-id", "").strip()
            if not settlement_id:
                continue

            print(f"    Settlement: {settlement_id} ({len(rows)} rows)")

            # Skip if already processed
            if settlement_id in processed_set:
                print(f"    ⏭️  Already processed")
                reports_skipped += 1
                continue

            if dry_run:
                transactions, summary = parse_settlement_rows(rows, marketplace_id)
                period = ""
                if summary:
                    period = (f" ({summary.get('settlement_start_date', '?')}"
                              f" to {summary.get('settlement_end_date', '?')})")
                print(f"    [DRY RUN] {len(transactions)} transactions{period}")
                total_transactions += len(transactions)
                reports_processed += 1
                continue

            # Create tracking
            import_id = create_data_import(
                marketplace_code,
                date.today(),
                import_type="sp_api_settlement"
            )

            pull_id = create_financial_pull_record(
                marketplace_code=marketplace_code,
                report_type=report_type,
                pull_date=date.today(),
                import_id=import_id,
                settlement_id=settlement_id,
                report_id=report_id,
                report_document_id=report_doc_id
            )

            # Parse and upsert
            transactions, summary = parse_settlement_rows(
                rows, marketplace_id, import_id
            )

            tx_count = upsert_settlement_transactions(transactions)
            print(f"    ✅ {tx_count} transactions")

            if summary:
                upsert_settlement_summary(summary)
                print(f"    ✅ Summary: {summary.get('settlement_start_date', '?')} "
                      f"to {summary.get('settlement_end_date', '?')}, "
                      f"total: {summary.get('total_amount', '?')} "
                      f"{summary.get('currency_code', '?')}")

            # Update tracking
            processing_time = int((time.time() - mp_start) * 1000)
            update_financial_pull_status(
                pull_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )
            update_data_import(
                import_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )

            total_transactions += tx_count
            reports_processed += 1
            processed_set.add(settlement_id)

        except Exception as e:
            error_msg = str(e)
            print(f"    ✗ Error: {error_msg}")
            errors.append({"report_id": report_id, "error": error_msg})

    processing_time = int((time.time() - mp_start) * 1000)

    return {
        "status": "completed" if not errors else "partial",
        "marketplace": marketplace_code,
        "reports_found": len(reports),
        "reports_processed": reports_processed,
        "reports_skipped": reports_skipped,
        "total_transactions": total_transactions,
        "errors": len(errors),
        "processing_time_ms": processing_time
    }


def main():
    parser = argparse.ArgumentParser(
        description="Backfill Settlement Reports from SP-API"
    )
    parser.add_argument(
        "--since",
        type=str,
        default=DEFAULT_SINCE,
        help=f"Backfill reports since this date (YYYY-MM-DD). Default: {DEFAULT_SINCE}"
    )
    parser.add_argument(
        "--marketplace",
        type=str,
        help="Specific marketplace to backfill (e.g., USA, CA, MX)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Download and parse but don't write to database"
    )

    args = parser.parse_args()

    since_date = f"{args.since}T00:00:00Z"

    # Determine marketplaces
    if args.marketplace:
        marketplaces = [args.marketplace.upper()]
    else:
        marketplaces = DEFAULT_MARKETPLACES

    # Validate
    for mp in marketplaces:
        if mp not in MARKETPLACE_IDS:
            print(f"Error: Invalid marketplace '{mp}'")
            sys.exit(1)

    print("=" * 60)
    print("SETTLEMENT REPORT BACKFILL")
    print(f"Since: {args.since}")
    print(f"Marketplaces: {', '.join(marketplaces)}")
    print(f"Dry run: {args.dry_run}")
    print("=" * 60)

    # Get access token
    print("\nGetting access token...")
    access_token = get_access_token()
    print("✓ Access token obtained")

    script_start = time.time()

    # Process each marketplace
    results = []
    for i, marketplace in enumerate(marketplaces):
        # Check timeout
        if (time.time() - script_start) > MAX_RUNTIME_SECONDS:
            print(f"\n⏱️  Approaching timeout — stopping before {marketplace}")
            break

        if i > 0:
            print(f"\nWaiting {MARKETPLACE_DELAY}s between marketplaces...")
            time.sleep(MARKETPLACE_DELAY)

        result = backfill_marketplace(
            access_token,
            marketplace,
            since_date,
            region="NA",
            dry_run=args.dry_run,
            start_time=script_start
        )
        results.append(result)

    # Summary
    print("\n" + "=" * 60)
    print("BACKFILL SUMMARY")
    print("=" * 60)

    total_reports = 0
    total_skipped = 0
    total_transactions = 0
    failed = 0

    for result in results:
        marketplace = result["marketplace"]
        status = result["status"]

        reports_processed = result.get("reports_processed", 0)
        skipped = result.get("reports_skipped", 0)
        transactions = result.get("total_transactions", 0)
        found = result.get("reports_found", 0)

        total_reports += reports_processed
        total_skipped += skipped
        total_transactions += transactions

        if status == "failed":
            failed += 1
            print(f"  {marketplace}: ✗ {result.get('error', 'Unknown error')}")
        else:
            icon = "✓" if status in ["completed", "dry_run"] else "⚠️"
            print(f"  {marketplace}: {icon} {reports_processed} new / "
                  f"{skipped} skipped / {found} total found, "
                  f"{transactions} transactions")

    total_time = int((time.time() - script_start))
    print(f"\nTotal: {total_reports} new reports, {total_skipped} skipped, "
          f"{total_transactions} transactions")
    print(f"Time: {total_time // 60}m {total_time % 60}s")

    if failed > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
