#!/usr/bin/env python3
"""
Pull Settlement Reports from SP-API

Settlement reports are auto-generated by Amazon every ~2 weeks.
Pattern: LIST available reports → DOWNLOAD each one (not create-poll-download).

Each settlement report contains per-order transaction-level fee breakdowns:
- Referral fees (Commission)
- FBA fulfillment fees
- Refunds
- Promotions/Coupons
- Shipping income
- Other fees

This is the PRIMARY data source for accurate CM2 calculation.

Usage:
    python pull_settlements.py                          # New reports since last pull
    python pull_settlements.py --since 2026-01-01       # Reports since date
    python pull_settlements.py --marketplace USA        # Single marketplace
    python pull_settlements.py --dry-run                # Test without DB writes

Environment Variables Required:
    SP_LWA_CLIENT_ID      - Login With Amazon Client ID
    SP_LWA_CLIENT_SECRET  - Login With Amazon Client Secret
    SP_REFRESH_TOKEN_NA   - North America refresh token
    SUPABASE_URL          - Supabase project URL
    SUPABASE_SERVICE_KEY  - Supabase service role key
"""

import os
import sys
import argparse
import time
from datetime import date, datetime, timedelta
from typing import Dict, List, Any, Optional

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.auth import get_access_token
from utils.financial_reports import (
    list_settlement_reports,
    download_settlement_report,
    parse_settlement_rows,
    FINANCIAL_REPORT_TYPES
)
from utils.inventory_reports import MARKETPLACE_IDS
from utils.db import (
    create_data_import,
    update_data_import,
    create_financial_pull_record,
    update_financial_pull_status,
    get_processed_settlement_ids,
    upsert_settlement_transactions,
    upsert_settlement_summary,
    MARKETPLACE_UUIDS,
)

# Rate limit between report downloads (seconds)
DOWNLOAD_DELAY = 10  # Increased from 5s - was getting 429s with 11 reports


def get_default_since_date() -> str:
    """
    Default: last 30 days for weekly pulls.
    Settlement reports are generated every ~2 weeks, so 30 days
    covers at least 1-2 new reports.
    """
    since = date.today() - timedelta(days=30)
    return since.strftime("%Y-%m-%dT00:00:00Z")


def pull_settlement_reports(
    access_token: str,
    since_date: str,
    region: str = "NA",
    dry_run: bool = False,
    max_reports: int = 100,
    list_marketplace: str = "USA"
) -> Dict[str, Any]:
    """
    Pull all new settlement reports for the NA region.

    Amazon's LIST API returns ALL settlement reports for the entire NA region
    regardless of marketplace filter. Each report contains transactions for
    multiple marketplaces (USA, CA, MX). This function:
    1. Lists reports once (using any NA marketplace)
    2. Downloads each report once
    3. Attributes each row to the correct marketplace using marketplace-name field

    Args:
        access_token: Valid SP-API access token
        since_date: ISO date string to list reports from
        region: API region
        dry_run: If True, don't write to database
        max_reports: Maximum number of reports to process
        list_marketplace: Marketplace to use for LIST API call (any NA marketplace works)

    Returns:
        Dict with pull statistics
    """
    start_time = time.time()
    report_type = FINANCIAL_REPORT_TYPES["SETTLEMENT"]

    print(f"\n{'='*60}")
    print(f"Settlement Reports — NA Region")
    print(f"Since: {since_date}")
    print(f"{'='*60}")

    # Step 1: List available settlement reports (any NA marketplace returns all)
    try:
        reports = list_settlement_reports(
            access_token, list_marketplace, region, since_date, max_reports
        )
    except Exception as e:
        print(f"  ✗ Error listing reports: {e}")
        return {
            "status": "failed",
            "marketplace": "NA",
            "error": str(e),
            "reports_processed": 0,
            "total_transactions": 0
        }

    if not reports:
        print(f"  No new settlement reports found")
        return {
            "status": "no_data",
            "marketplace": "NA",
            "reports_processed": 0,
            "total_transactions": 0
        }

    # Step 2: Check which settlement IDs we've already processed (globally)
    if not dry_run:
        processed_ids = get_processed_settlement_ids()
        processed_set = set(processed_ids)
        print(f"  Already processed: {len(processed_set)} settlement reports")
    else:
        processed_set = set()

    # Step 3: Process each report
    reports_processed = 0
    reports_skipped = 0
    total_transactions = 0
    errors = []

    for i, report in enumerate(reports):
        report_id = report.get("reportId", "")
        report_doc_id = report.get("reportDocumentId", "")
        created_time = report.get("createdTime", "")

        print(f"\n  Report {i+1}/{len(reports)}: {report_id}")
        print(f"    Created: {created_time}")
        print(f"    Document: {report_doc_id}")

        if not report_doc_id:
            print(f"    ⚠️  No reportDocumentId — skipping")
            continue

        # Download and peek at settlement ID before deciding to skip
        try:
            # Rate limit between downloads
            if i > 0:
                print(f"    Waiting {DOWNLOAD_DELAY}s (rate limit)...")
                time.sleep(DOWNLOAD_DELAY)

            # Download report
            rows = download_settlement_report(access_token, report_doc_id, region)
            print(f"    Downloaded: {len(rows)} rows")

            if not rows:
                print(f"    ⚠️  Empty report — skipping")
                continue

            # Get settlement ID from first row
            settlement_id = (rows[0].get("settlement-id") or "").strip()
            if not settlement_id:
                print(f"    ⚠️  No settlement ID in data — skipping")
                continue

            print(f"    Settlement ID: {settlement_id}")

            # Check if already processed
            if settlement_id in processed_set:
                print(f"    ⏭️  Already processed — skipping")
                reports_skipped += 1
                continue

            if dry_run:
                # Parse with per-row marketplace attribution
                transactions, summary = parse_settlement_rows(
                    rows, MARKETPLACE_UUIDS.get("USA", ""),
                    marketplace_uuids=MARKETPLACE_UUIDS
                )
                # Count by marketplace
                mp_counts = {}
                for tx in transactions:
                    mp_id = tx["marketplace_id"]
                    mp_counts[mp_id] = mp_counts.get(mp_id, 0) + 1
                mp_labels = {v: k for k, v in MARKETPLACE_UUIDS.items()}
                mp_summary = ", ".join(
                    f"{mp_labels.get(mp_id, mp_id)}: {count}"
                    for mp_id, count in sorted(mp_counts.items(), key=lambda x: -x[1])
                )
                print(f"    [DRY RUN] Would upsert {len(transactions)} transactions ({mp_summary})")
                if summary:
                    print(f"    [DRY RUN] Settlement period: "
                          f"{summary.get('settlement_start_date', '?')} to "
                          f"{summary.get('settlement_end_date', '?')}")
                    print(f"    [DRY RUN] Total amount: "
                          f"{summary.get('total_amount', '?')} "
                          f"{summary.get('currency_code', '?')}")
                total_transactions += len(transactions)
                reports_processed += 1
                continue

            # Create tracking records (use "NA" as marketplace since report spans region)
            import_id = create_data_import(
                "USA",  # tracking record marketplace (report listed via USA)
                date.today(),
                import_type="sp_api_settlement"
            )

            pull_id = create_financial_pull_record(
                marketplace_code="USA",
                report_type=report_type,
                pull_date=date.today(),
                import_id=import_id,
                settlement_id=settlement_id,
                report_id=report_id,
                report_document_id=report_doc_id
            )

            # Parse rows with per-row marketplace attribution
            transactions, summary = parse_settlement_rows(
                rows, MARKETPLACE_UUIDS.get("USA", ""),
                import_id=import_id,
                marketplace_uuids=MARKETPLACE_UUIDS
            )

            # Log marketplace breakdown
            mp_counts = {}
            for tx in transactions:
                mp_id = tx["marketplace_id"]
                mp_counts[mp_id] = mp_counts.get(mp_id, 0) + 1
            mp_labels = {v: k for k, v in MARKETPLACE_UUIDS.items()}
            for mp_id, count in sorted(mp_counts.items(), key=lambda x: -x[1]):
                print(f"    → {mp_labels.get(mp_id, mp_id)}: {count} transactions")

            # Upsert transactions (with correct per-row marketplace_id)
            tx_count = upsert_settlement_transactions(transactions)
            print(f"    ✅ Upserted {tx_count} transactions")

            # Upsert summary per marketplace
            # Summary uses the settlement's currency to determine marketplace
            if summary:
                upsert_settlement_summary(summary)
                print(f"    ✅ Settlement summary saved"
                      f" ({summary.get('settlement_start_date', '?')} to "
                      f"{summary.get('settlement_end_date', '?')})")

            # Update tracking
            processing_time = int((time.time() - start_time) * 1000)
            update_financial_pull_status(
                pull_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )
            update_data_import(
                import_id, "completed",
                row_count=tx_count,
                processing_time_ms=processing_time
            )

            total_transactions += tx_count
            reports_processed += 1
            processed_set.add(settlement_id)

        except Exception as e:
            error_msg = str(e)
            print(f"    ✗ Error: {error_msg}")
            errors.append({"report_id": report_id, "error": error_msg})

            if not dry_run:
                try:
                    if pull_id:
                        update_financial_pull_status(pull_id, "failed", error_message=error_msg)
                except Exception:
                    pass
                try:
                    if import_id:
                        update_data_import(import_id, "failed", error_message=error_msg)
                except Exception:
                    pass

    # Summary
    processing_time = int((time.time() - start_time) * 1000)

    result = {
        "status": "completed" if not errors else "partial",
        "marketplace": "NA",
        "reports_found": len(reports),
        "reports_processed": reports_processed,
        "reports_skipped": reports_skipped,
        "total_transactions": total_transactions,
        "errors": len(errors),
        "processing_time_ms": processing_time
    }

    if dry_run:
        result["status"] = "dry_run"

    return result


def main():
    parser = argparse.ArgumentParser(
        description="Pull Settlement Reports from SP-API"
    )
    parser.add_argument(
        "--since",
        type=str,
        help="List reports created since this date (YYYY-MM-DD). Default: last 30 days."
    )
    parser.add_argument(
        "--marketplace",
        type=str,
        help="Marketplace to use for LIST API call (default: USA). "
             "Note: All NA settlements are returned regardless of marketplace."
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Pull data but don't write to database"
    )
    parser.add_argument(
        "--max-reports",
        type=int,
        default=100,
        help="Maximum reports to process (default: 100)"
    )

    args = parser.parse_args()

    # Determine since date
    if args.since:
        since_date = f"{args.since}T00:00:00Z" if "T" not in args.since else args.since
    else:
        since_date = get_default_since_date()

    # Marketplace for listing (any NA marketplace returns all NA settlements)
    list_marketplace = (args.marketplace or "USA").upper()
    if list_marketplace not in MARKETPLACE_IDS:
        print(f"Error: Invalid marketplace '{list_marketplace}'")
        sys.exit(1)

    print("=" * 60)
    print("SETTLEMENT REPORT PULL")
    print(f"Since: {since_date}")
    print(f"List marketplace: {list_marketplace} (all NA settlements returned)")
    print(f"Max reports: {args.max_reports}")
    print(f"Dry run: {args.dry_run}")
    print("=" * 60)

    # Get access token
    print("\nGetting access token...")
    access_token = get_access_token()
    print("✓ Access token obtained")

    # Process all settlement reports (single run for entire NA region)
    result = pull_settlement_reports(
        access_token,
        since_date,
        region="NA",
        dry_run=args.dry_run,
        max_reports=args.max_reports,
        list_marketplace=list_marketplace
    )

    # Summary
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)

    status = result["status"]
    reports_processed = result.get("reports_processed", 0)
    transactions = result.get("total_transactions", 0)
    skipped = result.get("reports_skipped", 0)

    if status == "failed":
        print(f"  ✗ {result.get('error', 'Unknown error')}")
        sys.exit(1)
    else:
        status_icon = "✓" if status in ["completed", "dry_run"] else "⚠️"
        print(f"  {status_icon} {reports_processed} reports processed, "
              f"{transactions} transactions"
              f"{f', {skipped} skipped' if skipped else ''}")


if __name__ == "__main__":
    main()
